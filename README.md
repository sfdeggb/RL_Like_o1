# ğŸ§  Cot(chain of thought)& RL(Reinforcement learning) liked open ai preview model 

# ğŸš€é¡¹ç›®æ¦‚è¿°
è¯¥é¡¹ç›®ä½¿ç”¨`google/gemma-2-2b-it`æ¨¡å‹å®ç°ç±»ä¼¼äºo1æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ å’Œæ€ç»´é“¾æ¥æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›
# ğŸ’ªé¡¹ç›®ç»“æ„
- cotï¼š å®ç°æ€ç»´é“¾æ¨ç†çš„å®ç°
 - gradio ä½¿ç”¨gradioæ¡†æ¶è¿›è¡Œæ€ç»´é“¾æ¨ç†å±•ç¤º
 - ollama ä½¿ç”¨ollmamæ¥è¿›è¡Œæ€ç»´é“¾æ¨ç†å±•ç¤º
 - streamlitï¼š ä½¿ç”¨streamlitæ¥å®ç°æ€ç»´é“¾æ¨ç†
- rl_train :å®ç°åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹è®­ç»ƒ 
# ğŸ”¥å¦‚ä½•å¯åŠ¨
1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
`conda create -n your_env_name python=3.10
2. å®‰è£…ä¾èµ–\
`pip install -r requirements.txt`
3. è·å–æ¨¡å‹è®¿é—®æƒé™
3.1 ç™»å½•huggingface,ç‚¹å‡»[google/gemma-2-2b-it]()è·å–æ¨¡å‹è®¿é—®æƒé™ã€‚
é¦–å…ˆè¿è¡Œ`python access_token.py`å®ç°æœ¬åœ°ç™»å½•huggingface
4. é…ç½®config.yamlæ–‡ä»¶
config.yamlçš„é»˜è®¤é…ç½®å¦‚ä¸‹ï¼š
```
model_name: "google/gemma-2-2b-it" 
access_token: "***************************"
learning_rate: 1e-5
epochs_stage_1: 2
epochs_stage_2: 3
beta_kl: 0.1
alpha: 1.0
data_file: "./data/SCoRe_Dataset_zh.csv"
```
é…ç½®ä¸­çš„access_token éœ€è¦è‡ªå·±ç™»å½•huggingfaceè´¦æˆ·å»è·å–ã€‚
å¯å¤åˆ¶config.yaml.templeate åˆ°config.yamlä½¿å¾—é…ç½®ç”Ÿæ•ˆã€‚
`cp ./rl_train`<br>
`cp config.yaml.templeate config.yaml`

5. å¼ºåŒ–å­¦ä¹ å¯åŠ¨
python run.py -f config.yaml
6. æ€ç»´é“¾æ¨ç†å¯åŠ¨  
`cd cot`</br>
`cd gradio`

# ğŸŒç»“æœå±•ç¤º
æ€ç»´é“¾è¾“å‡ºï¼š
![alt text](image.png)
å¼ºåŒ–å­¦ä¹ è¾“å‡º
å¾…å†™
# ğŸ›¡ï¸å‚è€ƒè®ºæ–‡
[Google Training Language Models to Self-Correct via reinforcement learning](https://arxiv.org/abs/2409.12917)
